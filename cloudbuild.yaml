# Define the service account used by Cloud Build
serviceAccount: "gcp-sp@databricks-devops.iam.gserviceaccount.com"

# Specify the Docker images (replace with appropriate images)
images:
  - 'gcr.io/cloud-builders/git'  
  - 'timvancann/databricks-cli'

# Define substitutions for environment variables
substitutions:
  _DATABRICKS_HOST: 'https://adb-1499785588441012.12.azuredatabricks.net'
  _DATABRICKS_TOKEN: 'dapicd225a3be886969133e88a58e9afe2bd-3'

steps:
  # Step 1: Clone the notebook repository
  - name: 'gcr.io/cloud-builders/git' 
    args: ['clone', 'https://github.com/mayo8624/GCP-DEMO.git']
    dir: 'workspace'

  # Step 2: Deploy notebook to Databricks (using your preferred image)
  - name: 'timvancann/databricks-cli'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Configure Databricks CLI
        /usr/local/bin/databricks configure --token $_DATABRICKS_HOST 

        # Specific notebook deployment commands (replace with your commands)
        databricks workspace import -o --language PYTHON /workspace/abc/notebook.dbc /workspace/live

options:
  # Configure logs and notifications (optional)
  defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET


# steps:
#   # Step 1: Checkout the source code repository
#   - name: 'gcr.io/cloud-builders/git'
#     args: ['clone', 'https://github.com/mayo8624/GCP-DEMO.git']
#     dir: 'workspace' 

#   # Step 2: Configure Databricks CLI
#   - name: 'timvancann/databricks-cli'
#     entrypoint: 'bash'
#     args:
#       - '-c'
#       - |
#         # Prompt for Databricks Host URL
#         read -p "Enter Databricks Host URL (should begin with https://): " DATABRICKS_HOST
        
#         # Validate Databricks Host URL
#         if [[ ! $DATABRICKS_HOST =~ ^https:// ]]; then
#           echo "Error: The host does not start with https://"
#           exit 1
#         fi
        
#         # Configure Databricks CLI with token
#         echo "dapicd225a3be886969133e88a58e9afe2bd-3" | databricks configure --host "$DATABRICKS_HOST" --token

#   # Step 3: Import notebook into Databricks workspace
#   - name: 'timvancann/databricks-cli'
#     entrypoint: 'bash'
#     args:
#       - '-c'
#       - |
#         # Import notebook into Databricks workspace
#         databricks workspace import -o --language PYTHON /workspace/abc/notebook.dbc /workspace/live
        
#         # Additional Databricks CLI commands as needed
# options:
#   defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET
